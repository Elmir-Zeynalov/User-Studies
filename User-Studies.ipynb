{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-Studies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in pre_study before processing data: 154\n",
      "Number of rows in during_study before processing data: 469\n",
      "Number of rows in post_study before processing data: 122\n",
      "\n",
      "Duplicate 'CYSP' session IDs for participant 'G17P4': False\n",
      "Participant with ID 'grup16' in pre_study: False\n",
      "Participant with ID 'grup16' in during_study: False\n",
      "Participant with ID 'grup16' in post_study: False\n",
      "Participant with ID 'grup15' in pre_study: 0\n",
      "Participant with ID 'grup15' in during_study: 0\n",
      "Participant with ID 'grup15' in post_study: 0\n",
      "\n",
      "Rows in during_study with invalid session IDs before: 35\n",
      "Rows in during_study with invalid session IDs after: 0\n",
      "Participants in during_study with valid session counts (equal to 4): 79 = 316 rows\n",
      "Participant IDs present in during_study but not in pre_study or post_study:\n",
      "{'JOJOSIWA', 'g17p2', 'G17P6'}\n",
      "\n",
      "Number of rows in pre_study before processing data: 76\n",
      "Number of rows in during_study before processing data: 316\n",
      "Number of rows in post_study before processing data: 76\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read all files\n",
    "pre_study = pd.read_csv('Data/IN5060_fall24-pre-study.csv')\n",
    "during_study = pd.read_csv(\"Data/IN5060_fall24-during-study.csv\")\n",
    "post_study = pd.read_csv('Data/IN5060_fall24-post-study.csv')\n",
    "\n",
    "print(f\"Number of rows in pre_study before processing data: {pre_study.shape[0]}\")\n",
    "print(f\"Number of rows in during_study before processing data: {during_study.shape[0]}\")\n",
    "print(f\"Number of rows in post_study before processing data: {post_study.shape[0]}\\n\")\n",
    "\n",
    "session_id_col = \"Session ID (the last session that the participant has completed)\"\n",
    "participant_id_col = \"Participant ID (top-right corner of the screen)\"\n",
    "participant_id_during_col = \"Participant ID (top-right corner)\"\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------------\n",
    "# ---------------------- REMOVE DIRTY DATA --------------------------------------------------------------------------\n",
    "# -------------------------------------------------------------------------------------------------------------------\n",
    "pre_study = pre_study[pre_study[\"Please indicate if you have any of the following health problems.\"] != \"Test\"]\n",
    "during_study = during_study[~during_study[participant_id_during_col].str.contains(\"test\", case=False, na=False)]\n",
    "\n",
    "# Remove participant id \"grup16\"\n",
    "pre_study = pre_study[pre_study[participant_id_col] != \"grup16\"]\n",
    "during_study = during_study[during_study[participant_id_during_col] != \"grup16\"]\n",
    "post_study = post_study[post_study[participant_id_col] != \"grup16\"]\n",
    "\n",
    "# Remove participant ids containing \"group15\" in any dataset\n",
    "pre_study = pre_study[~pre_study[participant_id_col].str.contains(\"group15\", case=False)]\n",
    "during_study = during_study[~during_study[participant_id_during_col].str.contains(\"group15\", case=False)]\n",
    "post_study = post_study[~post_study[participant_id_col].str.contains(\"group15\", case=False)]\n",
    "\n",
    "# Remove duplicate session id CYSP for participant id G17P4\n",
    "g17p4_cysp = during_study[(during_study[participant_id_during_col] == \"G17P4\") & (during_study[session_id_col] == \"CYSP\")]\n",
    "g17p4_cysp_sorted = g17p4_cysp.sort_values(by=\"Timestamp\")\n",
    "if not g17p4_cysp_sorted.empty:\n",
    "    oldest_index = g17p4_cysp_sorted.index[0]\n",
    "    during_study.at[oldest_index, session_id_col] = \"ALICE\"\n",
    "\n",
    "# Print if there are duplicates for CYSP session ID for participant G17P4\n",
    "print(f\"Duplicate 'CYSP' session IDs for participant 'G17P4': {len(g17p4_cysp) > 1}\")\n",
    "\n",
    "# Print if any participant ID in any dataset contains \"grup16\"\n",
    "print(f\"Participant with ID 'grup16' in pre_study: {'grup16' in pre_study[participant_id_col].values}\")\n",
    "print(f\"Participant with ID 'grup16' in during_study: {'grup16' in during_study[participant_id_during_col].values}\")\n",
    "print(f\"Participant with ID 'grup16' in post_study: {'grup16' in post_study[participant_id_col].values}\")\n",
    "\n",
    "# Print the count of rows that had \"group15\" in the Participant ID for each dataset\n",
    "print(f\"Participant with ID 'grup15' in pre_study: {pre_study[pre_study[participant_id_col].str.contains('group15', case=False)].shape[0]}\")\n",
    "print(f\"Participant with ID 'grup15' in during_study: {during_study[during_study[participant_id_during_col].str.contains('group15', case=False)].shape[0]}\")\n",
    "print(f\"Participant with ID 'grup15' in post_study: {post_study[post_study[participant_id_col].str.contains('group15', case=False)].shape[0]}\")\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------------\n",
    "# ---------------------- ENSURE SESSION ID EQUALS VOYAGER, ILLIAC, CYSP OR ALICE ------------------------------------\n",
    "# -------------------------------------------------------------------------------------------------------------------\n",
    "switch_ids = ['VOYAGER', 'ILLIAC', 'CYSP', 'ALICE']\n",
    "switch_rows = during_study[during_study[participant_id_during_col]\n",
    "                            .str.contains('|'.join(switch_ids), case=False, na=False)]\n",
    "\n",
    "# Swap Participant ID and Session ID for these rows\n",
    "for index, row in switch_rows.iterrows():\n",
    "    during_study.at[index, participant_id_during_col] = row[session_id_col]\n",
    "    during_study.at[index, session_id_col] = row[participant_id_during_col]\n",
    "\n",
    "# Fix writing mistakes\n",
    "replacements = {\n",
    "    r'(?i)ALLICE': 'ALICE',\n",
    "    r'(?i)iliac': 'ILLIAC',\n",
    "    r'(?i)ILLIAD': 'ILLIAC',\n",
    "    r'(?i)Crysp': 'CYSP'\n",
    "}\n",
    "\n",
    "# Replace session IDs using the dictionary\n",
    "for old_value, new_value in replacements.items():\n",
    "    during_study[session_id_col] = \\\n",
    "        during_study[session_id_col].replace(\n",
    "            to_replace=old_value, value=new_value, regex=True)\n",
    "\n",
    "# After fixing swap and correcting writing, how many invalid sessions are left?\n",
    "def get_invalid_sessions(df):\n",
    "    return df[~df[session_id_col]\n",
    "              .str.contains(\"VOYAGER|ILLIAC|CYSP|ALICE\", case=False, na=False)]\n",
    "\n",
    "invalid_sessions = get_invalid_sessions(during_study)\n",
    "print(f\"\\nRows in during_study with invalid session IDs before: {invalid_sessions.shape[0]}\")\n",
    "\n",
    "# Invalid sessions contain 35 rows, they have been investigated and we can drop them\n",
    "during_study = during_study.drop(invalid_sessions.index)\n",
    "\n",
    "invalid_sessions = get_invalid_sessions(during_study)\n",
    "print(f\"Rows in during_study with invalid session IDs after: {invalid_sessions.shape[0]}\")\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------------\n",
    "# ---------------------- REMOVING PARTICIPANTS WHERE SESSION COUNT IS NOT 4 -----------------------------------------\n",
    "# -------------------------------------------------------------------------------------------------------------------\n",
    "# Group by Participant ID and check the number of unique session IDs\n",
    "session_count_per_participant = during_study.groupby(participant_id_during_col)[session_id_col].nunique()\n",
    "\n",
    "# Identify valid participants who have 4 unique session IDs\n",
    "valid_participants = session_count_per_participant[session_count_per_participant == 4].index\n",
    "\n",
    "# Display participants with valid session counts\n",
    "print(f\"Participants in during_study with valid session counts (equal to 4): {valid_participants.shape[0]} = {valid_participants.shape[0]*4} rows\")\n",
    "\n",
    "# Only keep valid participants\n",
    "during_study = during_study.query(f\"`{participant_id_during_col}` in @valid_participants\")\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------------\n",
    "# ---------------------- REMOVE INVALID PARTICIPANTS FROM PRE AND POST STUDY ----------------------------------------\n",
    "# -------------------------------------------------------------------------------------------------------------------\n",
    "valid_participant_ids = during_study[participant_id_during_col].unique()\n",
    "\n",
    "# Remove rows in pre_study and post_study where the participant ID is not present in during_study\n",
    "pre_study = pre_study[pre_study[participant_id_col].isin(valid_participant_ids)]\n",
    "post_study = post_study[post_study[participant_id_col].isin(valid_participant_ids)]\n",
    "\n",
    "# Pre and post study should have the same amount of participants and no duplicates\n",
    "pre_study = pre_study.sort_values(by=\"Timestamp\", ascending=False)\n",
    "pre_study = pre_study.drop_duplicates(subset=participant_id_col, keep='first')\n",
    "post_study = post_study.sort_values(by=\"Timestamp\", ascending=False)\n",
    "post_study = post_study.drop_duplicates(subset=participant_id_col, keep='first')\n",
    "\n",
    "common_participant_ids_pre = pre_study[participant_id_col].isin(post_study[participant_id_col])\n",
    "common_participant_ids_post = post_study[participant_id_col].isin(pre_study[participant_id_col])\n",
    "\n",
    "# This leaves us with 76 participants\n",
    "pre_study = pre_study[common_participant_ids_pre]\n",
    "post_study = post_study[common_participant_ids_post]\n",
    "\n",
    "# during_study should have 304 entries, we have 316 -> find the duplicates\n",
    "pre_post_participant_ids = set(pre_study[participant_id_col].unique()).intersection(post_study[participant_id_col].unique())\n",
    "\n",
    "# Find participant IDs that are in during_study but not in pre_study or post_study\n",
    "during_not_in_pre_post = set(valid_participant_ids) - pre_post_participant_ids\n",
    "print(f\"\\nParticipant IDs present in during_study but not in pre_study or post_study: {during_not_in_pre_pos}\")\n",
    "print(during_not_in_pre_post)\n",
    "\n",
    "#during_study = during_study.sort_values(by=participant_id_during_col)\n",
    "#participant_during = during_study[participant_id_during_col]\n",
    "#print(f\"\\nParticipant IDs in during_study: {participant_during}\")\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------------\n",
    "print(f\"\\nNumber of rows in pre_study before processing data: {pre_study.shape[0]}\")\n",
    "print(f\"Number of rows in during_study before processing data: {during_study.shape[0]}\")\n",
    "print(f\"Number of rows in post_study before processing data: {post_study.shape[0]}\")\n",
    "\n",
    "# Display all columns and expand display width\n",
    "pd.set_option('display.max_columns', None)     # Show all columns\n",
    "pd.set_option('display.width', 1000)           # Set the display width to fit large tables\n",
    "pd.set_option('display.max_colwidth', None)    # Show full column content without truncation\n",
    "pd.set_option('display.max_rows', None)        # Show all rows (remove this if there are too many rows)\n",
    "\n",
    "print(\"\\n\")\n",
    "#print(during_study.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# During Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note to Caroline: As an initial test i wanted to checkout if i managed to get anything out of this ANOVA thing. So, i started out by looking at the one-way ANOVA test in the \"during-study\" and looked at the \"I felt excited\" data. I looked at the SessionIDs and tried to use the ANOVA test to determine if there is any sort of differences in \"Excitement\" between the different SessionId. It looks like there are statistical differences, revealed by the p-value, and a post-hoc analysis is required. \n",
    "\n",
    "We can probably look at other \"feelings\" and see how those look like across the SesisonIds. I guess we are using the SessionIds (the different rhythm profiles) as the base groups but idk if we should look at some other way of grouping? SessionIds seems to be alright for now, we can probably provide some analysis on that and say f.ex \"people really liked the ILLIAC profile\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 2.2147760846846207\n",
      "p-value: 0.01105945548544588\n"
     ]
    }
   ],
   "source": [
    "# Perform ANOVA on \"I felt excited\" across different \"Session ID\" groups\n",
    "anova_results = stats.f_oneway(\n",
    "    *[during_study[during_study['Session ID (the last session that the participant has completed)'] == session]['I felt excited']\n",
    "      for session in during_study['Session ID (the last session that the participant has completed)'].unique()]\n",
    ")\n",
    "\n",
    "print(\"F-statistic:\", anova_results.statistic)\n",
    "print(\"p-value:\", anova_results.pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ANOVA test results show an F-statistic of approximately 1.76 and a p-value of 0.0066. Since the p-value is below the typical significance level (e.g., 0.05), we can conclude that there are statistically significant differences in excitement levels across the different session types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      group1    group2  meandiff   p-adj   lower   upper  reject\n",
      "0      ALICE   VOYAGER   -1.5000  0.9973 -6.1411  3.1411   False\n",
      "1      ALICE     ALICE   -0.8803  0.9972 -3.5973  1.8367   False\n",
      "2      ALICE     Alice    0.1667  1.0000 -3.2926  3.6259   False\n",
      "3      ALICE      CYSP   -1.0753  0.9835 -3.7913  1.6407   False\n",
      "4      ALICE      Cysp    1.5000  0.9973 -3.1411  6.1411   False\n",
      "5      ALICE    ILLIAC   -0.8514  0.9980 -3.5669  1.8642   False\n",
      "6      ALICE    Illiac   -1.5000  0.9973 -6.1411  3.1411   False\n",
      "7      ALICE   VOYAGER   -1.3592  0.9050 -4.0762  1.3579   False\n",
      "8      ALICE     alice    0.1000  1.0000 -3.0705  3.2705   False\n",
      "9      ALICE      cysp   -0.5000  1.0000 -3.5383  2.5383   False\n",
      "10     ALICE    illiac   -1.1667  0.9891 -4.2607  1.9274   False\n",
      "11     ALICE   voyager   -0.6111  1.0000 -3.5735  2.3512   False\n",
      "12   VOYAGER     ALICE    0.6197  1.0000 -3.1963  4.4358   False\n",
      "13   VOYAGER     Alice    1.6667  0.9881 -2.7090  6.0423   False\n",
      "14   VOYAGER      CYSP    0.4247  1.0000 -3.3907  4.2400   False\n",
      "15   VOYAGER      Cysp    3.0000  0.8120 -2.3591  8.3591   False\n",
      "16   VOYAGER    ILLIAC    0.6486  1.0000 -3.1663  4.4636   False\n",
      "17   VOYAGER    Illiac    0.0000  1.0000 -5.3591  5.3591   False\n",
      "18   VOYAGER   VOYAGER    0.1408  1.0000 -3.6752  3.9569   False\n",
      "19   VOYAGER     alice    1.6000  0.9868 -2.5511  5.7511   False\n",
      "20   VOYAGER      cysp    1.0000  0.9998 -3.0511  5.0511   False\n",
      "21   VOYAGER    illiac    0.3333  1.0000 -3.7597  4.4264   False\n",
      "22   VOYAGER   voyager    0.8889  0.9999 -3.1055  4.8833   False\n",
      "23     ALICE     Alice    1.0469  0.9392 -1.1866  3.2805   False\n",
      "24     ALICE      CYSP   -0.1951  0.9983 -0.8267  0.4366   False\n",
      "25     ALICE      Cysp    2.3803  0.6762 -1.4358  6.1963   False\n",
      "26     ALICE    ILLIAC    0.0289  1.0000 -0.6006  0.6585   False\n",
      "27     ALICE    Illiac   -0.6197  1.0000 -4.4358  3.1963   False\n",
      "28     ALICE   VOYAGER   -0.4789  0.3690 -1.1149  0.1571   False\n",
      "29     ALICE     alice    0.9803  0.8133 -0.7731  2.7336   False\n",
      "30     ALICE      cysp    0.3803  0.9998 -1.1209  1.8815   False\n",
      "31     ALICE    illiac   -0.2864  1.0000 -1.8975  1.3247   False\n",
      "32     ALICE   voyager    0.2692  1.0000 -1.0717  1.6100   False\n",
      "33     Alice      CYSP   -1.2420  0.8184 -3.4744  0.9903   False\n",
      "34     Alice      Cysp    1.3333  0.9985 -3.0423  5.7090   False\n",
      "35     Alice    ILLIAC   -1.0180  0.9500 -3.2498  1.2137   False\n",
      "36     Alice    Illiac   -1.6667  0.9881 -6.0423  2.7090   False\n",
      "37     Alice   VOYAGER   -1.5258  0.5328 -3.7594  0.7078   False\n",
      "38     Alice     alice   -0.0667  1.0000 -2.8341  2.7008   False\n",
      "39     Alice      cysp   -0.6667  0.9997 -3.2816  1.9483   False\n",
      "40     Alice    illiac   -1.3333  0.9083 -4.0129  1.3462   False\n",
      "41     Alice   voyager   -0.7778  0.9983 -3.3041  1.7485   False\n",
      "42      CYSP      Cysp    2.5753  0.5526 -1.2400  6.3907   False\n",
      "43      CYSP    ILLIAC    0.2240  0.9930 -0.4011  0.8491   False\n",
      "44      CYSP    Illiac   -0.4247  1.0000 -4.2400  3.3907   False\n",
      "45      CYSP   VOYAGER   -0.2838  0.9553 -0.9154  0.3478   False\n",
      "46      CYSP     alice    1.1753  0.5626 -0.5764  2.9271   False\n",
      "47      CYSP      cysp    0.5753  0.9873 -0.9240  2.0747   False\n",
      "48      CYSP    illiac   -0.0913  1.0000 -1.7007  1.5180   False\n",
      "49      CYSP   voyager    0.4642  0.9948 -0.8745  1.8030   False\n",
      "50      Cysp    ILLIAC   -2.3514  0.6933 -6.1663  1.4636   False\n",
      "51      Cysp    Illiac   -3.0000  0.8120 -8.3591  2.3591   False\n",
      "52      Cysp   VOYAGER   -2.8592  0.3772 -6.6752  0.9569   False\n",
      "53      Cysp     alice   -1.4000  0.9960 -5.5511  2.7511   False\n",
      "54      Cysp      cysp   -2.0000  0.9130 -6.0511  2.0511   False\n",
      "55      Cysp    illiac   -2.6667  0.6100 -6.7597  1.4264   False\n",
      "56      Cysp   voyager   -2.1111  0.8655 -6.1055  1.8833   False\n",
      "57    ILLIAC    Illiac   -0.6486  1.0000 -4.4636  3.1663   False\n",
      "58    ILLIAC   VOYAGER   -0.5078  0.2613 -1.1373  0.1217   False\n",
      "59    ILLIAC     alice    0.9514  0.8414 -0.7997  2.7024   False\n",
      "60    ILLIAC      cysp    0.3514  0.9999 -1.1471  1.8498   False\n",
      "61    ILLIAC    illiac   -0.3153  1.0000 -1.9238  1.2932   False\n",
      "62    ILLIAC   voyager    0.2402  1.0000 -1.0975  1.5780   False\n",
      "63    Illiac   VOYAGER    0.1408  1.0000 -3.6752  3.9569   False\n",
      "64    Illiac     alice    1.6000  0.9868 -2.5511  5.7511   False\n",
      "65    Illiac      cysp    1.0000  0.9998 -3.0511  5.0511   False\n",
      "66    Illiac    illiac    0.3333  1.0000 -3.7597  4.4264   False\n",
      "67    Illiac   voyager    0.8889  0.9999 -3.1055  4.8833   False\n",
      "68   VOYAGER     alice    1.4592  0.2177 -0.2942  3.2125   False\n",
      "69   VOYAGER      cysp    0.8592  0.7880 -0.6421  2.3604   False\n",
      "70   VOYAGER    illiac    0.1925  1.0000 -1.4186  1.8036   False\n",
      "71   VOYAGER   voyager    0.7480  0.8156 -0.5928  2.0889   False\n",
      "72     alice      cysp   -0.6000  0.9995 -2.8189  1.6189   False\n",
      "73     alice    illiac   -1.2667  0.8263 -3.5613  1.0280   False\n",
      "74     alice   voyager   -0.7111  0.9961 -2.8248  1.4025   False\n",
      "75      cysp    illiac   -0.6667  0.9978 -2.7749  1.4416   False\n",
      "76      cysp   voyager   -0.1111  1.0000 -2.0208  1.7986   False\n",
      "77    illiac   voyager    0.5556  0.9994 -1.4417  2.5528   False\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for Tukey's HSD test\n",
    "session_data = during_study[['Session ID (the last session that the participant has completed)', 'I felt excited']].dropna()\n",
    "session_data.columns = ['SessionID', 'Excitement']\n",
    "\n",
    "tukey_results = pairwise_tukeyhsd(endog=session_data['Excitement'], groups=session_data['SessionID'], alpha=0.05)\n",
    "\n",
    "tukey_summary = tukey_results.summary()\n",
    "\n",
    "# Convert the summary to a pandas DataFrame for easier viewing\n",
    "tukey_df = pd.DataFrame(data=tukey_summary.data[1:], columns=tukey_summary.data[0])\n",
    "\n",
    "print(tukey_df)\n",
    "\n",
    "# Display the results\n",
    "#print(tukey_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Study"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
