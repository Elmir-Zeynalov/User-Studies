{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-Studies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in pre_study before processing data: 154\n",
      "Number of rows in during_study before processing data: 469\n",
      "Number of rows in post_study before processing data: 122\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Duplicate 'CYSP' session IDs for participant 'G17P4': False\n",
      "Participant with ID 'grup16' in pre_study: False\n",
      "Participant with ID 'grup16' in during_study: False\n",
      "Participant with ID 'grup16' in post_study: False\n",
      "Participant with ID 'grup15' in pre_study: 0\n",
      "Participant with ID 'grup15' in during_study: 0\n",
      "Participant with ID 'grup15' in post_study: 0\n",
      "\n",
      "Rows in during_study with invalid session IDs before: 35\n",
      "Rows in during_study with invalid session IDs after: 0\n",
      "Participants in during_study with valid session counts (equal to 4): 79 = 316 rows\n",
      "\n",
      "Participant IDs present in during_study but not in pre_study or post_study: {'JOJOSIWA', 'g17p2', 'G17P6'}\n",
      "Number of rows in during_study after removing invalid participants: 304\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Number of rows in pre_study before processing data: 76\n",
      "Number of rows in during_study before processing data: 304\n",
      "Number of rows in post_study before processing data: 76\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read all files\n",
    "pre_study = pd.read_csv('Data/IN5060_fall24-pre-study.csv')\n",
    "during_study = pd.read_csv(\"Data/IN5060_fall24-during-study.csv\")\n",
    "post_study = pd.read_csv('Data/IN5060_fall24-post-study.csv')\n",
    "\n",
    "print(f\"Number of rows in pre_study before processing data: {pre_study.shape[0]}\")\n",
    "print(f\"Number of rows in during_study before processing data: {during_study.shape[0]}\")\n",
    "print(f\"Number of rows in post_study before processing data: {post_study.shape[0]}\")\n",
    "print(f\"\\n-------------------------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "session_id_col = \"Session ID (the last session that the participant has completed)\"\n",
    "participant_id_col = \"Participant ID (top-right corner of the screen)\"\n",
    "participant_id_during_col = \"Participant ID (top-right corner)\"\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------------\n",
    "# ---------------------- REMOVE DIRTY DATA --------------------------------------------------------------------------\n",
    "# -------------------------------------------------------------------------------------------------------------------\n",
    "pre_study = pre_study[pre_study[\"Please indicate if you have any of the following health problems.\"] != \"Test\"]\n",
    "during_study = during_study[~during_study[participant_id_during_col].str.contains(\"test\", case=False, na=False)]\n",
    "\n",
    "# Remove participant id \"grup16\"\n",
    "pre_study = pre_study[pre_study[participant_id_col] != \"grup16\"]\n",
    "during_study = during_study[during_study[participant_id_during_col] != \"grup16\"]\n",
    "post_study = post_study[post_study[participant_id_col] != \"grup16\"]\n",
    "\n",
    "# Remove participant ids containing \"group15\" in any dataset\n",
    "pre_study = pre_study[~pre_study[participant_id_col].str.contains(\"group15\", case=False)]\n",
    "during_study = during_study[~during_study[participant_id_during_col].str.contains(\"group15\", case=False)]\n",
    "post_study = post_study[~post_study[participant_id_col].str.contains(\"group15\", case=False)]\n",
    "\n",
    "# Remove duplicate session id CYSP for participant id G17P4\n",
    "g17p4_cysp = during_study[(during_study[participant_id_during_col] == \"G17P4\") & (during_study[session_id_col] == \"CYSP\")]\n",
    "g17p4_cysp_sorted = g17p4_cysp.sort_values(by=\"Timestamp\")\n",
    "if not g17p4_cysp_sorted.empty:\n",
    "    oldest_index = g17p4_cysp_sorted.index[0]\n",
    "    during_study.at[oldest_index, session_id_col] = \"ALICE\"\n",
    "\n",
    "# Print if there are duplicates for CYSP session ID for participant G17P4\n",
    "print(f\"Duplicate 'CYSP' session IDs for participant 'G17P4': {len(g17p4_cysp) > 1}\")\n",
    "\n",
    "# Print if any participant ID in any dataset contains \"grup16\"\n",
    "print(f\"Participant with ID 'grup16' in pre_study: {'grup16' in pre_study[participant_id_col].values}\")\n",
    "print(f\"Participant with ID 'grup16' in during_study: {'grup16' in during_study[participant_id_during_col].values}\")\n",
    "print(f\"Participant with ID 'grup16' in post_study: {'grup16' in post_study[participant_id_col].values}\")\n",
    "\n",
    "# Print the count of rows that had \"group15\" in the Participant ID for each dataset\n",
    "print(f\"Participant with ID 'grup15' in pre_study: {pre_study[pre_study[participant_id_col].str.contains('group15', case=False)].shape[0]}\")\n",
    "print(f\"Participant with ID 'grup15' in during_study: {during_study[during_study[participant_id_during_col].str.contains('group15', case=False)].shape[0]}\")\n",
    "print(f\"Participant with ID 'grup15' in post_study: {post_study[post_study[participant_id_col].str.contains('group15', case=False)].shape[0]}\")\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------------\n",
    "# ---------------------- ENSURE SESSION ID EQUALS VOYAGER, ILLIAC, CYSP OR ALICE ------------------------------------\n",
    "# -------------------------------------------------------------------------------------------------------------------\n",
    "switch_ids = ['VOYAGER', 'ILLIAC', 'CYSP', 'ALICE']\n",
    "switch_rows = during_study[during_study[participant_id_during_col]\n",
    "                            .str.contains('|'.join(switch_ids), case=False, na=False)]\n",
    "\n",
    "# Swap Participant ID and Session ID for these rows\n",
    "for index, row in switch_rows.iterrows():\n",
    "    during_study.at[index, participant_id_during_col] = row[session_id_col]\n",
    "    during_study.at[index, session_id_col] = row[participant_id_during_col]\n",
    "\n",
    "# Fix writing mistakes\n",
    "replacements = {\n",
    "    r'(?i)ALLICE': 'ALICE',\n",
    "    r'(?i)iliac': 'ILLIAC',\n",
    "    r'(?i)ILLIAD': 'ILLIAC',\n",
    "    r'(?i)Crysp': 'CYSP'\n",
    "}\n",
    "\n",
    "# Replace session IDs using the dictionary\n",
    "for old_value, new_value in replacements.items():\n",
    "    during_study[session_id_col] = \\\n",
    "        during_study[session_id_col].replace(\n",
    "            to_replace=old_value, value=new_value, regex=True)\n",
    "\n",
    "# After fixing swap and correcting writing, how many invalid sessions are left?\n",
    "def get_invalid_sessions(df):\n",
    "    return df[~df[session_id_col]\n",
    "              .str.contains(\"VOYAGER|ILLIAC|CYSP|ALICE\", case=False, na=False)]\n",
    "\n",
    "invalid_sessions = get_invalid_sessions(during_study)\n",
    "print(f\"\\nRows in during_study with invalid session IDs before: {invalid_sessions.shape[0]}\")\n",
    "\n",
    "# Invalid sessions contain 35 rows, they have been investigated and we can drop them\n",
    "during_study = during_study.drop(invalid_sessions.index)\n",
    "\n",
    "invalid_sessions = get_invalid_sessions(during_study)\n",
    "print(f\"Rows in during_study with invalid session IDs after: {invalid_sessions.shape[0]}\")\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------------\n",
    "# ---------------------- REMOVING PARTICIPANTS WHERE SESSION COUNT IS NOT 4 -----------------------------------------\n",
    "# -------------------------------------------------------------------------------------------------------------------\n",
    "# Group by Participant ID and check the number of unique session IDs\n",
    "session_count_per_participant = during_study.groupby(participant_id_during_col)[session_id_col].nunique()\n",
    "\n",
    "# Identify valid participants who have 4 unique session IDs\n",
    "valid_participants = session_count_per_participant[session_count_per_participant == 4].index\n",
    "\n",
    "# Display participants with valid session counts\n",
    "print(f\"Participants in during_study with valid session counts (equal to 4): {valid_participants.shape[0]} = {valid_participants.shape[0]*4} rows\")\n",
    "\n",
    "# Only keep valid participants\n",
    "during_study = during_study.query(f\"`{participant_id_during_col}` in @valid_participants\")\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------------\n",
    "# ---------------------- REMOVE INVALID PARTICIPANTS FROM PRE AND POST STUDY ----------------------------------------\n",
    "# -------------------------------------------------------------------------------------------------------------------\n",
    "valid_participant_ids = during_study[participant_id_during_col].unique()\n",
    "\n",
    "# Remove rows in pre_study and post_study where the participant ID is not present in during_study\n",
    "pre_study = pre_study[pre_study[participant_id_col].isin(valid_participant_ids)]\n",
    "post_study = post_study[post_study[participant_id_col].isin(valid_participant_ids)]\n",
    "\n",
    "# Pre and post study should have the same amount of participants and no duplicates\n",
    "pre_study = pre_study.sort_values(by=\"Timestamp\", ascending=False)\n",
    "pre_study = pre_study.drop_duplicates(subset=participant_id_col, keep='first')\n",
    "post_study = post_study.sort_values(by=\"Timestamp\", ascending=False)\n",
    "post_study = post_study.drop_duplicates(subset=participant_id_col, keep='first')\n",
    "\n",
    "common_participant_ids_pre = pre_study[participant_id_col].isin(post_study[participant_id_col])\n",
    "common_participant_ids_post = post_study[participant_id_col].isin(pre_study[participant_id_col])\n",
    "\n",
    "# This leaves us with 76 participants\n",
    "pre_study = pre_study[common_participant_ids_pre]\n",
    "post_study = post_study[common_participant_ids_post]\n",
    "\n",
    "# During_study should have 304 entries, we have 316 -> find the duplicates\n",
    "pre_post_participant_ids = set(pre_study[participant_id_col].unique()).intersection(post_study[participant_id_col].unique())\n",
    "during_not_in_pre_post = set(valid_participant_ids) - pre_post_participant_ids\n",
    "print(f\"\\nParticipant IDs present in during_study but not in pre_study or post_study: {during_not_in_pre_post}\")\n",
    "\n",
    "participants_to_remove = {'JOJOSIWA', 'g17p2', 'G17P6'}\n",
    "during_study = during_study[~during_study[participant_id_during_col].isin(participants_to_remove)]\n",
    "print(\"Number of rows in during_study after removing invalid participants:\", len(during_study))\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------------\n",
    "print(f\"\\n-------------------------------------------------------------------------------------------------------\\n\")\n",
    "print(f\"Number of rows in pre_study before processing data: {pre_study.shape[0]}\")\n",
    "print(f\"Number of rows in during_study before processing data: {during_study.shape[0]}\")\n",
    "print(f\"Number of rows in post_study before processing data: {post_study.shape[0]}\")\n",
    "\n",
    "# Display all columns and expand display width\n",
    "pd.set_option('display.max_columns', None)     # Show all columns\n",
    "pd.set_option('display.width', 1000)           # Set the display width to fit large tables\n",
    "pd.set_option('display.max_colwidth', None)    # Show full column content without truncation\n",
    "pd.set_option('display.max_rows', None)        # Show all rows (remove this if there are too many rows)\n",
    "\n",
    "print(\"\\n\")\n",
    "#print(during_study.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------What describes you the best?---------------------------------------------\n",
      "Student/semi-professional musician: 9 participants\n",
      "Avid music listener: 32 participants\n",
      "Professional musician: 1 participants\n",
      "Not particularly interested in music: 7 participants\n",
      "\n",
      "------------------------------------------------Gender?--------------------------------------------------------\n",
      "Prefer not to say: 0 participants\n",
      "Male: 52 participants\n",
      "Female: 24 participants\n",
      "\n",
      "------------------------Please add if you have any comments, suggestions, or requests.-------------------------\n",
      "Non-empty comments, suggestions, or requests:\n",
      "- fix the tracking landscape. It's invisible and gets in the way when doing almost anything that requires the mouse. The consistent downloading makes it very hard to keep tapping in rhythm due to download pop-ups.\n",
      "- The db felt broken and unfinished, fun and frustrating at the same time.\n",
      "- It would be more fun with more instruments and if the db actually listened to my input\n",
      "- The last beat profile was a bit chaotic. There was just a lot going on.\n",
      "- Felt like an absolute waste of my time. It doesnt sound like music, sounds more like random drumming which sometimes accidentaly match my input, nevertheless sounding bad. When i give it ONE input to finally get it to shut up it wont even do that. It is like a disloyal dog\n",
      "- I found the drumming sound while recording quite disrupting.\n",
      "- I wish the response was more coherent to my input. It felt completely random\n",
      "- Be able to record instruments individually\n",
      "- Overall, I did enjoy the drummer bot. The most exiting session was ILLIAC, the most annoying.. CYSP and VOYAGER. Greetings :)\n",
      "- A bit too heavy on the cymbals, maybe. And in general, after a while of testing around, it seemed very strongly like the melodies followed the same \"recipe\" instrument-wise\n",
      "- he is very weird. i feel sorry for him. he is not able to start on a syncopation!\n",
      "- The DB was boring, no creativity in the music, the website is annoying and are not responsive at all.\n",
      "- Great beat\n",
      "- Would be nice to have more input then space when you try to have high BPM.\n",
      "- fyi on firefox constatly having files donwload created a pop up that disabled my inputs unless i remvoed the pop up\n",
      "- beat never matched correlation between reference point and the next key. didn't feel responsive. distracting to hear the beat playing while hearing a new one. didn't feel like I knew where the \"player\" was in the track ever.\n",
      "- i got a bit bored after some time, and i got really confused as they were very different responses\n",
      "- Very confusing, I didn't know when I did something or when db did something. Also difficult to know where in the beat I was when making more.\n",
      "- Would like to have some more creative options\n"
     ]
    }
   ],
   "source": [
    "# Role\n",
    "print(f\"\\n--------------------------------------What describes you the best?---------------------------------------------\")\n",
    "column_of_interest = \"What describes you the best?\"\n",
    "answers_to_count = [\n",
    "    \"Student/semi-professional musician\",\n",
    "    \"Avid music listener\",\n",
    "    \"Professional musician\",\n",
    "    \"Not particularly interested in music\"\n",
    "]\n",
    "\n",
    "counts = {answer: pre_study[pre_study[column_of_interest] == answer].shape[0] for answer in answers_to_count}\n",
    "for answer, count in counts.items():\n",
    "    print(f\"{answer}: {count} participants\")\n",
    "\n",
    "# Gender - this is skewed as there are more than double the amount of males - could run statistical significance test\n",
    "print(f\"\\n------------------------------------------------Gender?--------------------------------------------------------\")\n",
    "column_of_interest = \"Gender?\"\n",
    "answers_to_count = [\n",
    "    \"Prefer not to say\",\n",
    "    \"Male\",\n",
    "    \"Female\"\n",
    "]\n",
    "\n",
    "counts = {answer: pre_study[pre_study[column_of_interest] == answer].shape[0] for answer in answers_to_count}\n",
    "for answer, count in counts.items():\n",
    "    print(f\"{answer}: {count} participants\")\n",
    "\n",
    "# Comments\n",
    "print(f\"\\n------------------------Please add if you have any comments, suggestions, or requests.-------------------------\")\n",
    "column_of_interest = \"Please add if you have any comments, suggestions, or requests.\"\n",
    "non_empty_comments = post_study[post_study[column_of_interest].str.strip().ne(\"\") & post_study[column_of_interest].notna()]\n",
    "\n",
    "print(\"Non-empty comments, suggestions, or requests:\")\n",
    "for comment in non_empty_comments[column_of_interest]:\n",
    "    print(f\"- {comment.strip()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# During Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note to Caroline: As an initial test i wanted to checkout if i managed to get anything out of this ANOVA thing. So, i started out by looking at the one-way ANOVA test in the \"during-study\" and looked at the \"I felt excited\" data. I looked at the SessionIDs and tried to use the ANOVA test to determine if there is any sort of differences in \"Excitement\" between the different SessionId. It looks like there are statistical differences, revealed by the p-value, and a post-hoc analysis is required. \n",
    "\n",
    "We can probably look at other \"feelings\" and see how those look like across the SesisonIds. I guess we are using the SessionIds (the different rhythm profiles) as the base groups but idk if we should look at some other way of grouping? SessionIds seems to be alright for now, we can probably provide some analysis on that and say f.ex \"people really liked the ILLIAC profile\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 2.4253079621397267\n",
      "p-value: 0.006674073237232363\n"
     ]
    }
   ],
   "source": [
    "# Perform ANOVA on \"I felt excited\" across different \"Session ID\" groups\n",
    "anova_results = stats.f_oneway(\n",
    "    *[during_study[during_study['Session ID (the last session that the participant has completed)'] == session]['I felt excited']\n",
    "      for session in during_study['Session ID (the last session that the participant has completed)'].unique()]\n",
    ")\n",
    "\n",
    "print(\"F-statistic:\", anova_results.statistic)\n",
    "print(\"p-value:\", anova_results.pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ANOVA test results show an F-statistic of approximately 1.76 and a p-value of 0.0066. Since the p-value is below the typical significance level (e.g., 0.05), we can conclude that there are statistically significant differences in excitement levels across the different session types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     group1   group2  meandiff   p-adj   lower   upper  reject\n",
      "0     ALICE    ALICE   -0.9242  0.9936 -3.6453  1.7968   False\n",
      "1     ALICE    Alice    0.1667  1.0000 -3.2942  3.6275   False\n",
      "2     ALICE     CYSP   -1.0735  0.9786 -3.7934  1.6464   False\n",
      "3     ALICE     Cysp    1.5000  0.9959 -3.1432  6.1432   False\n",
      "4     ALICE   ILLIAC   -0.8188  0.9978 -3.5382  1.9005   False\n",
      "5     ALICE   Illiac   -1.5000  0.9959 -6.1432  3.1432   False\n",
      "6     ALICE  VOYAGER   -1.3955  0.8715 -4.1160  1.3249   False\n",
      "7     ALICE    alice    0.1000  1.0000 -3.0719  3.2719   False\n",
      "8     ALICE     cysp   -0.5000  1.0000 -3.5397  2.5397   False\n",
      "9     ALICE   illiac   -1.1667  0.9851 -4.2621  1.9288   False\n",
      "10    ALICE  voyager   -0.6111  0.9999 -3.5748  2.3526   False\n",
      "11    ALICE    Alice    1.0909  0.9058 -1.1471  3.3289   False\n",
      "12    ALICE     CYSP   -0.1493  0.9998 -0.8044  0.5058   False\n",
      "13    ALICE     Cysp    2.4242  0.6296 -1.3955  6.2440   False\n",
      "14    ALICE   ILLIAC    0.1054  1.0000 -0.5473  0.7581   False\n",
      "15    ALICE   Illiac   -0.5758  1.0000 -4.3955  3.2440   False\n",
      "16    ALICE  VOYAGER   -0.4713  0.4356 -1.1288  0.1862   False\n",
      "17    ALICE    alice    1.0242  0.7464 -0.7343  2.7827   False\n",
      "18    ALICE     cysp    0.4242  0.9988 -1.0828  1.9312   False\n",
      "19    ALICE   illiac   -0.2424  1.0000 -1.8590  1.3741   False\n",
      "20    ALICE  voyager    0.3131  0.9998 -1.0340  1.6603   False\n",
      "21    Alice     CYSP   -1.2402  0.8019 -3.4768  0.9964   False\n",
      "22    Alice     Cysp    1.3333  0.9975 -3.0443  5.7110   False\n",
      "23    Alice   ILLIAC   -0.9855  0.9518 -3.2214  1.2504   False\n",
      "24    Alice   Illiac   -1.6667  0.9838 -6.0443  2.7110   False\n",
      "25    Alice  VOYAGER   -1.5622  0.4785 -3.7995  0.6751   False\n",
      "26    Alice    alice   -0.0667  1.0000 -2.8353  2.7020   False\n",
      "27    Alice     cysp   -0.6667  0.9995 -3.2828  1.9495   False\n",
      "28    Alice   illiac   -1.3333  0.8933 -4.0141  1.3474   False\n",
      "29    Alice  voyager   -0.7778  0.9973 -3.3052  1.7497   False\n",
      "30     CYSP     Cysp    2.5735  0.5363 -1.2454  6.3925   False\n",
      "31     CYSP   ILLIAC    0.2547  0.9792 -0.3931  0.9025   False\n",
      "32     CYSP   Illiac   -0.4265  1.0000 -4.2454  3.3925   False\n",
      "33     CYSP  VOYAGER   -0.3220  0.8984 -0.9746  0.3306   False\n",
      "34     CYSP    alice    1.1735  0.5502 -0.5832  2.9302   False\n",
      "35     CYSP     cysp    0.5735  0.9837 -0.9313  2.0784   False\n",
      "36     CYSP   illiac   -0.0931  1.0000 -1.7077  1.5214   False\n",
      "37     CYSP  voyager    0.4624  0.9930 -0.8823  1.8072   False\n",
      "38     Cysp   ILLIAC   -2.3188  0.6926 -6.1374  1.4997   False\n",
      "39     Cysp   Illiac   -3.0000  0.7924 -8.3615  2.3615   False\n",
      "40     Cysp  VOYAGER   -2.8955  0.3455 -6.7149  0.9238   False\n",
      "41     Cysp    alice   -1.4000  0.9940 -5.5530  2.7530   False\n",
      "42     Cysp     cysp   -2.0000  0.8983 -6.0529  2.0529   False\n",
      "43     Cysp   illiac   -2.6667  0.5904 -6.7616  1.4283   False\n",
      "44     Cysp  voyager   -2.1111  0.8478 -6.1073  1.8851   False\n",
      "45   ILLIAC   Illiac   -0.6812  1.0000 -4.4997  3.1374   False\n",
      "46   ILLIAC  VOYAGER   -0.5767  0.1387 -1.2269  0.0736   False\n",
      "47   ILLIAC    alice    0.9188  0.8557 -0.8370  2.6747   False\n",
      "48   ILLIAC     cysp    0.3188  0.9999 -1.1850  1.8227   False\n",
      "49   ILLIAC   illiac   -0.3478  0.9999 -1.9615  1.2658   False\n",
      "50   ILLIAC  voyager    0.2077  1.0000 -1.1359  1.5513   False\n",
      "51   Illiac  VOYAGER    0.1045  1.0000 -3.7149  3.9238   False\n",
      "52   Illiac    alice    1.6000  0.9822 -2.5530  5.7530   False\n",
      "53   Illiac     cysp    1.0000  0.9997 -3.0529  5.0529   False\n",
      "54   Illiac   illiac    0.3333  1.0000 -3.7616  4.4283   False\n",
      "55   Illiac  voyager    0.8889  0.9999 -3.1073  4.8851   False\n",
      "56  VOYAGER    alice    1.4955  0.1840 -0.2621  3.2531   False\n",
      "57  VOYAGER     cysp    0.8955  0.7204 -0.6104  2.4014   False\n",
      "58  VOYAGER   illiac    0.2289  1.0000 -1.3867  1.8444   False\n",
      "59  VOYAGER  voyager    0.7844  0.7457 -0.5615  2.1303   False\n",
      "60    alice     cysp   -0.6000  0.9992 -2.8199  1.6199   False\n",
      "61    alice   illiac   -1.2667  0.8070 -3.5623  1.0290   False\n",
      "62    alice  voyager   -0.7111  0.9942 -2.8257  1.4035   False\n",
      "63     cysp   illiac   -0.6667  0.9966 -2.7759  1.4425   False\n",
      "64     cysp  voyager   -0.1111  1.0000 -2.0217  1.7995   False\n",
      "65   illiac  voyager    0.5556  0.9989 -1.4426  2.5537   False\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for Tukey's HSD test\n",
    "session_data = during_study[['Session ID (the last session that the participant has completed)', 'I felt excited']].dropna()\n",
    "session_data.columns = ['SessionID', 'Excitement']\n",
    "\n",
    "tukey_results = pairwise_tukeyhsd(endog=session_data['Excitement'], groups=session_data['SessionID'], alpha=0.05)\n",
    "\n",
    "tukey_summary = tukey_results.summary()\n",
    "\n",
    "# Convert the summary to a pandas DataFrame for easier viewing\n",
    "tukey_df = pd.DataFrame(data=tukey_summary.data[1:], columns=tukey_summary.data[0])\n",
    "\n",
    "print(tukey_df)\n",
    "\n",
    "# Display the results\n",
    "#print(tukey_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Study"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
